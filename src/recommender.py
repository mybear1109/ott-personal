import requests
import streamlit as st
from src.data_fetcher import fetch_movies_by_genre
import json
import re
import os
import logging
from typing import List, Dict, Set, Tuple
import pandas as pd
from huggingface_hub import InferenceClient

# TMDb API ì„¤ì •
API_KEY = st.secrets["MOVIEDB_API_KEY"]
BASE_URL = "https://api.themoviedb.org/3"


### ğŸŸ¢ **ì˜í™” IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜í™”ì˜ ì„¸ë¶€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°**
def get_movie_details(movie_id):
    url = f"{BASE_URL}/movie/{movie_id}?api_key={API_KEY}&language=ko-KR"
    response = requests.get(url)
    if response.status_code == 200:
        return response.json()
    return None


### ğŸŸ¢ **íŠ¸ë Œë”© ì˜í™” ê°€ì ¸ì˜¤ê¸°**
def get_trending_movies():
    url = f"{BASE_URL}/trending/movie/week?api_key={API_KEY}&language=ko-KR"
    response = requests.get(url)
    movies = response.json().get("results", [])

    movie_list = []
    for movie in movies:
        details = get_movie_details(movie["id"])
        if details:
            movie_list.append(format_movie_details(details))
    return movie_list


### ğŸŸ¢ **ì¶”ì²œ ì˜í™” ê°€ì ¸ì˜¤ê¸°**
def get_recommendations(movie_id):
    url = f"{BASE_URL}/movie/{movie_id}/recommendations?api_key={API_KEY}&language=ko-KR"
    response = requests.get(url)
    movies = response.json().get("results", [])

    movie_list = []
    for movie in movies:
        details = get_movie_details(movie["id"])
        if details:
            movie_list.append(format_movie_details(details))
    return movie_list


### ğŸŸ¢ **ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜ ì¶”ì²œ ì˜í™”**
def get_personalized_recommendations(profile):
    preferred_genres = profile.get("preferred_genres", [])
    genre_map = {
        "ì•¡ì…˜": 28, "ì½”ë¯¸ë””": 35, "ë“œë¼ë§ˆ": 18,
        "ë¡œë§¨ìŠ¤": 10749, "ìŠ¤ë¦´ëŸ¬": 53, "SF": 878, "ì• ë‹ˆë©”ì´ì…˜": 16,
        "íŒíƒ€ì§€": 14, "ê³µí¬": 27, "ë‹¤íë©˜í„°ë¦¬": 99, "ì—­ì‚¬": 36
    }
    genre_ids = [genre_map[g] for g in preferred_genres if g in genre_map]

    movie_list = []
    for genre_id in genre_ids:
        movies = fetch_movies_by_genre(genre_id)
        for movie in movies:
            details = get_movie_details(movie["id"])
            if details:
                movie_list.append(format_movie_details(details))

    return movie_list[:10]


### ğŸŸ¢ **ë¬´ë“œ(ê°ì •) ê¸°ë°˜ ì˜í™” ì¶”ì²œ**
def get_mood_based_recommendations(mood):
    mood_to_genre = {
        "í–‰ë³µí•œ": [35, 10751],  # ì½”ë¯¸ë””, ê°€ì¡±
        "ìŠ¬í”ˆ": [18, 10749],  # ë“œë¼ë§ˆ, ë¡œë§¨ìŠ¤
        "ì‹ ë‚˜ëŠ”": [28, 12],  # ì•¡ì…˜, ëª¨í—˜
        "ë¡œë§¨í‹±í•œ": [10749, 35],  # ë¡œë§¨ìŠ¤, ì½”ë¯¸ë””
        "ë¬´ì„œìš´": [27, 53],  # ê³µí¬, ìŠ¤ë¦´ëŸ¬
        "ë¯¸ìŠ¤í„°ë¦¬í•œ": [9648, 80],  # ë¯¸ìŠ¤í„°ë¦¬, ë²”ì£„
        "íŒíƒ€ì§€í•œ": [14, 12],  # íŒíƒ€ì§€, ëª¨í—˜
        "í¸ì•ˆí•œ": [99, 10770],  # ë‹¤íë©˜í„°ë¦¬, TV ì˜í™”
        "ì¶”ì–µì„ ë– ì˜¬ë¦¬ëŠ”": [10752, 36],  # ì „ìŸ, ì—­ì‚¬
        "SF ê°™ì€": [878, 28],  # SF, ì•¡ì…˜
    }

    genre_ids = mood_to_genre.get(mood, [35])  # ê¸°ë³¸ê°’ì€ ì½”ë¯¸ë””
    movie_list = []

    for genre_id in genre_ids:
        movies = fetch_movies_by_genre(genre_id)
        for movie in movies:
            details = get_movie_details(movie["id"])
            if details:
                movie_list.append(format_movie_details(details))

    return movie_list[:10]


### ğŸŸ¢ **í‚¤ì›Œë“œ ê¸°ë°˜ ì˜í™” ê²€ìƒ‰**
def get_movies_by_keyword(keyword):
    url = f"{BASE_URL}/search/keyword?api_key={API_KEY}&query={keyword}"
    response = requests.get(url)
    keywords = response.json().get("results", [])

    if not keywords:
        return []

    keyword_id = keywords[0]["id"]
    url = f"{BASE_URL}/discover/movie?api_key={API_KEY}&with_keywords={keyword_id}&language=ko-KR"
    response = requests.get(url)
    movies = response.json().get("results", [])

    movie_list = []
    for movie in movies:
        details = get_movie_details(movie["id"])
        if details:
            movie_list.append(format_movie_details(details))

    return movie_list


### ğŸŸ¢ **ì˜í™” ë¦¬ë·° ê°€ì ¸ì˜¤ê¸°**
def get_movie_reviews(movie_id):
    url = f"{BASE_URL}/movie/{movie_id}/reviews?api_key={API_KEY}&language=ko-KR"
    response = requests.get(url)
    reviews = response.json().get("results", [])

    review_list = []
    for review in reviews:
        review_list.append({
            "author": review["author"],
            "rating": review["author_details"]["rating"],
            "content": review["content"][:200] + "..." if len(review["content"]) > 200 else review["content"],
            "created_at": review["created_at"],
        })
    return review_list


### ğŸŸ¢ **íŠ¸ë Œë””í•œ TV ì‡¼ ê°€ì ¸ì˜¤ê¸°**
def get_trending_tv_shows():
    url = f"{BASE_URL}/trending/tv/week?api_key={API_KEY}&language=ko-KR"
    response = requests.get(url)
    shows = response.json().get("results", [])

    show_list = []
    for show in shows:
        show_list.append(format_movie_details(show, is_tv=True))
    return show_list


### ğŸŸ¢ **íŠ¸ë Œë””í•œ ì¸ë¬¼ ê°€ì ¸ì˜¤ê¸°**
def get_trending_people():
    url = f"{BASE_URL}/trending/person/week?api_key={API_KEY}&language=ko-KR"
    response = requests.get(url)
    people = response.json().get("results", [])

    people_list = []
    for person in people:
        people_list.append({
            "name": person["name"],
            "popularity": person["popularity"],
            "known_for": [work["title"] for work in person["known_for"] if "title" in work],
            "profile_path": f"https://image.tmdb.org/t/p/w500{person['profile_path']}" if person.get("profile_path") else None
        })
    return people_list


### ğŸŸ¢ **ì˜í™” ë°ì´í„° í¬ë§·íŒ… í•¨ìˆ˜ (ì¤„ê±°ë¦¬ ì¼ë¶€ í‘œì‹œ + ë” ë³´ê¸° ë²„íŠ¼)**
def format_movie_details(details, is_tv=False):
    short_overview = details["overview"][:100] + "..." if len(details["overview"]) > 100 else details["overview"]
    
    return {
        "title": details["title"] if not is_tv else details["name"],
        "overview": short_overview,
        "full_overview": details["overview"],
        "release_date": details["release_date"] if not is_tv else details["first_air_date"],
        "vote_average": details["vote_average"],
        "poster_path": f"https://image.tmdb.org/t/p/w500{details['poster_path']}" if details.get("poster_path") else None
    }


def get_huggingface_token():
    """í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” Streamlit secretsì—ì„œ Hugging Face API í† í°ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return st.secrets.get("HUGGINGFACE_API_TOKEN")

def clean_input(text: str) -> str:
    """ë¶ˆí•„ìš”í•œ ë‹¨ì–´(í•´ì¤˜, ì•Œë ¤ì¤˜ ë“±)ë¥¼ ì œê±°í•œ ì‚¬ìš©ì ì…ë ¥ì„ ë°˜í™˜"""
    return re.sub(r"\b(í•´ì¤˜|ì•Œë ¤ì¤˜|ì„¤ëª…í•´ ì¤˜|ë§í•´ ì¤˜)\b", "", text, flags=re.IGNORECASE).strip()

def generate_text_via_api(prompt: str, model_name: str = "google/gemma-2-9b-it"):
    """Hugging Face APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    token = get_huggingface_token()
    client = InferenceClient(model=model_name, api_key=token)
    response = client.text_generation(prompt=prompt)
    return response

def get_user_info_with_default(user_data: Dict[str, str]) -> Dict[str, str]:
    """ì‚¬ìš©ì ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê³ , ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    user_info = st.session_state.get("user_info", user_data)
    st.session_state["user_info"] = user_info
    return user_info

